

DBSCAN is a density based clustering algorithm defined by two parameters “eps” and “min_points”. Two points are near neighbours if they are within a distance “eps” from each other. A point is a core point if it and its near neighbours number at least some value “min_points”. A point is “reachable” if it is within eps of any core point(s). A cluster is determined by finding the first core point and then looking at each point in the core to find any further core points, then adding in any points that are reachable from any core point in the cluster.

Attention! In this implementation of DBSCAN points which are not core points in more than one cluster but are reachable from more than one cluster appear in all clusters they are reachable from. This was by design as I wanted each cluster to include all points that met the basic requirements of the algorithm. This also has the advantage that the results are independent of the order points are listed in the data – some implementations place these points in the first cluster they are found to be part of and they are not included in any further clusters. This can result in clusters with less than min_points which does not happen with this implementation. The disadvantage is the total number of points in all clusters and noise can exceed the total number of points. Depending on what the clusters mean you may want to handle “shared” points differently. Due to the way the clusters are built in this implementation, this code not easily modified to handle shared points in any different manner.

To start the clustering process, the class is called with suitable choices for the two parameters “eps” and “min_points”. See the Demo for example code. The cluster function itself is called with a set of data called “points”. This is a list of lists or tuples (as defined in Python) with the first two values representing an x and y of a spatial location. Additional members of the lists or tuples are ignored so points can be labeled or have weights or additional information following the x,y values. It would be a very minor tweak to cluster in 3D – the calculation of the point separation would need to have a z component and the points themselves would need to have three values prior to any other labels.

As a first step the algorithm finds all the near neighbours that lie within a distance “eps” of the each point in turn. Points are referenced only by an integer which is their index in the list of points – ie the first point is “0”, the second “1” etc. as usual for Python indices. A dictionary is created with keys being each point number with the values being all near-neighbours for that point. Any point with at least “min_points” (including itself) near neighbours will be a core point and part of a cluster. These points are also saved as a set of proto_cores. Any point with at least one near neighbour could be part of some cluster and all such points are saved as a set of working points (wp). Points with no near neighbours are never part of a cluster and will end up as noise points – from this point they are effectively ignored except for the step building the list of noise points. It is not necessary to retain the actual separation distances; the only data returned is the dictionary of near neighbours and the two sets proto_cores and wp.

The second step is to start with a point that is in the set proto_cores. This point will be a core point and the start of a cluster. We need to find all the core points that will be in this cluster. Basically for each near neighbour of the first core point which is also a core point we add that point to the cluster we are building and add all its near neighbours to the list of points to check as possible core points for that cluster. The features of Python sets is central to this implementation as they provide an automatic inclusion test to ensure that only new found points add to the cluster – those already found to be in the cluster do not add again. Once all the points have been tested, and all the points they linked to as well, we have found all the core points in that cluster.

The next step is to check each core point for near neighbours that are reachable but not core points in the cluster we are building. Again we use Python set inclusion to test for new points and ignore those already found. This is the step which places shared points in more than one cluster. At the end of this process we also use the point indexes we have been working with to rebuild the full cluster point list using the actual data points including any labels and weights.

For each cluster that is built, core points found to be in the cluster are also removed from the list of proto-cores. We then iterate over the remaining proto_cores until all proto_cores are assigned to cluster. At this point all clusters have been found. Any points not in a cluster are noise points and a list of these is generated. A summary list of clusters and their location (average over x and average over y for all the points in the cluster) is generated as well as the full list of clusters, the individual points in them, and a full list of noise points.
